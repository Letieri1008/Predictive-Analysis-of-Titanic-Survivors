{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e49c57-11bf-4b3e-a80b-d6402fd8ca86",
   "metadata": {},
   "source": [
    "# Predictive Analysis of Titanic Survivors with Python and Scikit-learn\n",
    "\n",
    "This machine learning mini-project is for study purposes and good practices to be applied in other futures analyses \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fdba0-c2a0-4586-964a-6f1bcdf103de",
   "metadata": {},
   "source": [
    "### Prepare The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2eb58-b4e1-40a9-a4ce-f41a8ed8e6af",
   "metadata": {},
   "source": [
    "### First, open CMD or your space working jupyter lab with the cooding for install any more libraries necessary.\n",
    "\n",
    "- pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e884972-f160-4835-afe1-61306170ee9f",
   "metadata": {},
   "source": [
    "### Import Libraries and Scikits-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d994516f-655f-4d13-bc46-9e7bb455cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396729c3-d91e-4a77-acd4-fc8746f908ba",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36034986-8586-482f-b788-2ba65ef51766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91078a58-fbfb-4b23-b517-4475f59b36d4",
   "metadata": {},
   "source": [
    "### Removing values Null in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3631bd-18bf-4109-9875-36b040511a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset nulls:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Test dataset nulls:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"Train dataset nulls:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nTest dataset nulls:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d740e9-c989-41af-a7ba-6b52a5143099",
   "metadata": {},
   "source": [
    "### Handle Missing values\n",
    "\n",
    "- We now need to fill in the blanks to make a more accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f03199-0c2e-4626-a790-3a2735c8602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Age\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
    "\n",
    "# Fill missing Embarked (training only)\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
    "\n",
    "# Fill missing Fare (test only)\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n",
    "\n",
    "# If you want, drop Cabin column (too many NaNs)\n",
    "train_df = train_df.drop(columns=['Cabin'])\n",
    "test_df = test_df.drop(columns=['Cabin'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76566b91-d867-4af4-be77-156f51eb2eb0",
   "metadata": {},
   "source": [
    "### Convert categorical variables to numeric\n",
    "\n",
    "- The purpose is to transform categorical variables (text or label) into integers. This is very important, because the Sex column is now numeric, ready to use in machine learning models, which don't understand text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a65958fe-e5a3-40a0-8fa8-fa8da7ef75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode 'Sex'\n",
    "train_df['Sex'] = le.fit_transform(train_df['Sex'])\n",
    "test_df['Sex'] = le.transform(test_df['Sex'])\n",
    "\n",
    "# Encode 'Embarked'\n",
    "train_df['Embarked'] = le.fit_transform(train_df['Embarked'])\n",
    "test_df['Embarked'] = le.transform(test_df['Embarked'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cf168-d8ff-4635-82fc-8056c289d7ba",
   "metadata": {},
   "source": [
    "### Select Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1634fbf0-4f4e-469f-a331-6ef895ab76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = train_df[features]\n",
    "y = train_df['Survived']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53113b7-c563-4054-a1ee-0175b61ae8c5",
   "metadata": {},
   "source": [
    "### Train the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4672498-bf59-4c57-93a0-35c99d9228e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8044692737430168\n",
      "[[90 15]\n",
      " [20 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       105\n",
      "           1       0.78      0.73      0.76        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f204788-0d51-4f54-98a2-5895f30c3e46",
   "metadata": {},
   "source": [
    "### Actual percentage of survivors in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe1e4bd0-44d7-4505-8d6b-63c353d11d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate: 38.38383838383838 %\n"
     ]
    }
   ],
   "source": [
    "# Taxa de sobrevivÃªncia real\n",
    "survival_rate = train_df['Survived'].mean()  # valor entre 0 e 1\n",
    "print(\"Survival rate:\", survival_rate*100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0714a-e704-4d9a-80de-759e492c227e",
   "metadata": {},
   "source": [
    "### Comporation survival Male and Female\n",
    "\n",
    "- Result of the sexes that had the greatest chance of survival\n",
    "- 0 = woman\n",
    "- 1 = man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7b970a7-91c7-4049-bf07-faa81ddd98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate by Sex (%):\n",
      "Sex\n",
      "0    74.203822\n",
      "1    18.890815\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "survival_by_sex = train_df.groupby('Sex')['Survived'].mean() * 100\n",
    "print(\"Survival rate by Sex (%):\")\n",
    "print(survival_by_sex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6490ee-0285-462f-8b9a-400c11f64855",
   "metadata": {},
   "source": [
    "In conclusion, this analysis could be better, with other more accurate techniques that perform better, example: Random Forest, What it is: An ensemble of multiple decision trees that vote on the final prediction.Why it's effective:Handles mixed categorical and continuous features well.\n",
    "\n",
    "Captures non-linear interactions between variables, such as age + class + gender.\n",
    "\n",
    "Less sensitive to outliers and overfitting than a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc2fe3-4856-43c5-97ba-f3428b3bd70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
